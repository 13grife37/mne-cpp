\input{_UserGuide.tex}

\begin{document}

\pagenumbering{gobble}
	
\lhead{\sc{User Guide: RTMU}}	
\title{User Guide: RTMU}
\vspace{3 in}
\maketitle

\includegraphics[width = \linewidth]{figures/mne-cpp.png}

\clearpage

\pagenumbering{arabic}

\tableofcontents

\clearpage

\lstset { %
	language=C++,
	backgroundcolor=\color{black!5}, % set backgroundcolor
	basicstyle=\footnotesize,% basic font setting
}

\section{Installation}

Since the project integrates into MNE-CPP and thus is directed at developers, there are no precompiled binaries or programs to install. The following tutorial explains all necessary steps to download and work with the results of this software project.

\begin{aims}
	\item[\hspace*{11mm} Qt Framework] Because MNE-CPP depends on the Qt framework, it must be installed. Therefore, you must download and install it.
\end{aims}

\begin{aims}
	\item[\hspace*{11mm} MNE-CPP Source Code] We recommend using Git to get the MNE-CPP source code, as you can simply clone / fork one of MNE-CPP's repositories.
\end{aims}

\begin{aims}
	\item[\hspace*{11mm} Compiling the Source Code] Since Qt creator is automatically installed when you install the Qt framework, it is easiest to use its build-in compiler. You must first run the \textit{mne-cpp.pro} file, then run \textit{qmake} and finally start a build of the project. After this, all binaries can be found inside the \textit{bin} folder.
\end{aims}

For more details, see \url{http://wiki.mne-cpp.org/index.php/Portal:Getting_Started}.

\clearpage

\section{Detailed Example}

This section should illustrate the use of the classes \textit{GeometryInfo} and \textit{Interpolation} by providing a detailed example.

\subsection{GeometryInfo}

This class provides three features: sensor-to-mesh mapping, surface constrained distance calculation and bad channel filtering.

\subsubsection{Sensor Projecting}

The method \textit{GeometryInfo::projectSensors} allows sensor-to-mesh mapping. This is needed because sensor positions may be somewhat above the vertices of the used mesh:\\
\begin{figure}[h]
	\begin{center}
		\includegraphics[width=10cm]{figures/sensorToMeshMapping.png}
		\caption{Sensor must be assigned to the best-matching vertex}
	\end{center}
\end{figure}
\\
The method receives two arguments: one MNEBemSurface and a QVector of Vector3f objects (Eigen representation of 3D coordinates). Said vector must contain the absolute positions of the sensors in 3D space.\\
Thus, a MNEBemSurface must be obtained first: 
\begin{lstlisting}
// extract MNEBemSurface from file
QFile t_filesensorSurfaceVV(QDir::currentPath()
		+ "/mne-cpp-test-data/subjects/sample/bem/sample-5120-bem.fif");
MNEBem t_sensorSurfaceVV(t_filesensorSurfaceVV);
MNEBemSurface surface = t_sensorSurfaceVV[0];
\end{lstlisting}

After that the sensor positions must be extracted:

\begin{lstlisting}
// extract FiffEvoked object from file
QFile t_fileEvoked(QDir::currentPath()
			+ "/mne-cpp-test-data/MEG/sample/sample_audvis-ave.fif");
fiff_int_t setno = 0;
QPair<QVariant, QVariant> baseline(QVariant(), 0);
FiffEvoked evoked = FiffEvoked(t_fileEvoked, setno, baseline);

// for MEG sensors (use magnetometers only)
QVector<Vector3f> megSensors;

for( const FiffChInfo &info : evoked.info.chs) {
	if(info.kind == FIFFV_MEG_CH && info.unit == FIFF_UNIT_T) {
		megSensors.push_back(info.chpos.r0);
	}
}


// for EEG sensors
QVector<Vector3f> eegSensors;
    
for( const FiffChInfo &info : evoked.info.chs) {
	if(info.kind == FIFFV_EEG_CH && info.unit == FIFF_UNIT_V) {
		eegSensors.push_back(info.chpos.r0);
	}
}
\end{lstlisting}

\begin{center}
\textit{Note: EEG sensors may need co-registration.}
\end{center}

The method \textit{GeometryInfo::projectSensors} returns a pointer to a vector of indices that point to the best matching vertices of the passed mesh:
\begin{lstlisting}
 QSharedPointer<QVector<qint32>> pVecMappedSubset;
 pVecMappedSubset = GeometryInfo::projectSensors(surface, megSensors);
\end{lstlisting}

A very simplified example further illustrates this:

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=6cm]{figures/sensorMappingSimpleBefore.png}
		\caption{Sensors are red, A-D are vertex IDs / indices}
	\end{center}
\end{figure}

%this is just to fix umbrueche
\clearpage

The algorithm would map the sensors as follows:

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=5cm]{figures/sensorMappingSimpleAfter.png}
		\caption{Mapped sensors}
	\end{center}
\end{figure}

The output vector thus would be:
\[
\begin{pmatrix} A & C \end{pmatrix}
\]

\subsubsection{Surface Constrained Distance Calculation}

In order to interpolate signals, distances between vertices are of significant interest. Because using euclidian distances for further calculations is very imprecise, we provided a method for calculating surface constrained distances.

\begin{figure}[h]
	\centering
	\begin{minipage}[b]{0.46\textwidth}
		\includegraphics[width=\textwidth]{figures/scdcEuclid.png}
		\caption{Euclidian distance}
	\end{minipage}
	\hfill
	\begin{minipage}[b]{0.46\textwidth}
		\includegraphics[width=\textwidth]{figures/scdcPrecise.png}
		\caption{Precise SCD}
	\end{minipage}
\end{figure}


\clearpage

\input{disp3dNavigation.tex}

  
\end{document}
